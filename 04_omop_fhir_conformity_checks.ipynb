{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "930d7ad2",
   "metadata": {},
   "source": [
    "# OMOP / FHIR Conformity Checks + CT.gov & CDC Context (Updated)\n",
    "\n",
    "This notebook extends the governance scorecard by adding:\n",
    "- **OMOP / FHIR / vocabulary** conformity (standards)\n",
    "- **ClinicalTrials.gov** portfolio context (feasibility proxy from median duration & enrollment)\n",
    "- **CDC** public-health timeliness (external signal)\n",
    "\n",
    "It combines these with the basic OpenFDA governance metrics into an expanded **RWD Governance Scorecard** with components:\n",
    "**Completeness, Consistency, Timeliness, Conformity, Standards, Context**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7dbf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, requests, pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from scripts.scorecard import (\n",
    "    compute_basic_metrics, score, plot_scorecard,\n",
    "    omop_conformity, fhir_conformity, vocabulary_format_score, standards_score\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b2153d-f1d0-437c-86bb-f5952a3f36c2",
   "metadata": {},
   "source": [
    "## 1) OpenFDA sample (as before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a915941f-8d8a-46da-a680-39e529b1e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull a small OpenFDA adverse events sample\n",
    "BASE = 'https://api.fda.gov/drug/event.json'\n",
    "params = {'search': 'receivedate:[20240101+TO+20251231]', 'limit': 100}\n",
    "\n",
    "try:\n",
    "    payload = requests.get(BASE, params=params, timeout=30).json()\n",
    "    results = payload.get('results', [])\n",
    "except Exception as e:\n",
    "    print(\"OpenFDA fetch failed:\", e)\n",
    "    results = []\n",
    "\n",
    "def flatten(rec):\n",
    "    return {\n",
    "        'safetyreportid': rec.get('safetyreportid'),\n",
    "        'receiptdate': rec.get('receiptdate'),\n",
    "        'occurcountry': rec.get('occurcountry'),\n",
    "        'serious': rec.get('serious'),\n",
    "        'companynumb': rec.get('companynumb'),\n",
    "    }\n",
    "\n",
    "df = pd.DataFrame([flatten(r) for r in results])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d4e2ed-28fe-4406-95e3-4d09fe606e85",
   "metadata": {},
   "source": [
    "## 2) Basic governance metrics (OpenFDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3befe86-9948-4e7e-9b98-f8cb72407d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_fields = ['safetyreportid','receiptdate','occurcountry','serious']\n",
    "basic = compute_basic_metrics(df, required_fields)\n",
    "basic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbe1488-57a0-4b0e-9e10-cc7766dc819b",
   "metadata": {},
   "source": [
    "## 3) OMOP / FHIR / Vocabulary (Standards)\n",
    "\n",
    "- **OMOP**: minimal required columns present + non-null coverage (illustrative)\n",
    "- **FHIR**: minimal required keys across a small synthetic bundle (illustrative)\n",
    "- **Vocabulary**: regex proxy (e.g., ICD-10-like format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819f4a9f-b4d0-4653-b488-a6a871b9a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OMOP: illustrate \"low\" on OpenFDA-like structure\n",
    "omop_like = pd.DataFrame({\n",
    "    'drug_exposure_id': pd.Series(dtype='Int64'),\n",
    "    'person_id': pd.Series(dtype='Int64'),\n",
    "    'drug_concept_id': pd.Series(dtype='Int64'),\n",
    "    'drug_exposure_start_date': pd.Series(dtype='string'),\n",
    "})\n",
    "omop_score = omop_conformity(omop_like, table='drug_exposure')\n",
    "\n",
    "# Synthetic high-conformity OMOP (for comparison, not used in final aggregate)\n",
    "omop_synth = pd.DataFrame({\n",
    "    'drug_exposure_id': range(1, 6),\n",
    "    'person_id': [101,102,103,104,105],\n",
    "    'drug_concept_id': [19019073,19019073,1539403,1547504,1539403],\n",
    "    'drug_exposure_start_date': pd.date_range('2024-01-01', periods=5).astype(str)\n",
    "})\n",
    "omop_synth_score = omop_conformity(omop_synth, table='drug_exposure')\n",
    "\n",
    "# FHIR: minimal AdverseEvent bundle (synthetic)\n",
    "fhir_bundle = [\n",
    "    {'resourceType':'AdverseEvent','id':'ae1','subject':{'reference':'Patient/1'},'dateRecorded':'2024-10-01'},\n",
    "    {'resourceType':'AdverseEvent','id':'ae2','subject':{'reference':'Patient/2'},'dateRecorded':'2024-11-15'},\n",
    "]\n",
    "fhir_score = fhir_conformity(fhir_bundle, resource_type='AdverseEvent')\n",
    "\n",
    "# Vocabulary proxy: ICD-10-like format check\n",
    "pattern_icd10 = r'^[A-TV-Z][0-9][A-Z0-9](?:\\.[A-Z0-9]{1,4})?$'\n",
    "df_codes = pd.DataFrame({'diagnosis_code': ['C34.1','I10','E11.9','1234','XYZ']})\n",
    "vocab_score = vocabulary_format_score(df_codes, 'diagnosis_code', pattern_icd10)\n",
    "\n",
    "# Aggregate to \"standards\"\n",
    "standards = standards_score({'omop': omop_score, 'fhir': fhir_score, 'vocab': vocab_score})\n",
    "omop_score, omop_synth_score, fhir_score, vocab_score, standards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee21ca1-fc48-4e61-b2f4-e15ed9f936ae",
   "metadata": {},
   "source": [
    "## 4) ClinicalTrials.gov portfolio context (reuses saved summary if present)\n",
    "\n",
    "This section computes basic **portfolio proxies**:\n",
    "- Median **duration** (months)\n",
    "- Median **enrollment**\n",
    "\n",
    "If `data/ctgov_summary.json` exists (from your other notebook), we use it; otherwise we fetch from the API directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6e88fa-4c9e-4f2b-9224-5932571885d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctgov_cache = DATA_DIR / \"ctgov_summary.json\"\n",
    "\n",
    "def fetch_ctgov(expr=\"oncology\", max_rnk=300):\n",
    "    BASE = \"https://clinicaltrials.gov/api/query/study_fields\"\n",
    "    params = {\n",
    "        \"expr\": expr,\n",
    "        \"fields\": \"NCTId,OverallStatus,StartDate,CompletionDate,EnrollmentCount\",\n",
    "        \"min_rnk\": 1,\n",
    "        \"max_rnk\": max_rnk,\n",
    "        \"fmt\": \"json\"\n",
    "    }\n",
    "    r = requests.get(BASE, params=params, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()[\"StudyFieldsResponse\"][\"StudyFields\"]\n",
    "    return data\n",
    "\n",
    "def to_dt(s):\n",
    "    if s is None: return None\n",
    "    for fmt in (\"%B %Y\", \"%Y-%m\", \"%Y-%m-%d\", \"%Y\"):\n",
    "        try: return datetime.strptime(s, fmt)\n",
    "        except: pass\n",
    "    return None\n",
    "\n",
    "if ctgov_cache.exists():\n",
    "    ct = json.loads(ctgov_cache.read_text())\n",
    "else:\n",
    "    try:\n",
    "        ct = fetch_ctgov(\"oncology\", 300)\n",
    "        ctgov_cache.write_text(json.dumps(ct))\n",
    "    except Exception as e:\n",
    "        print(\"CT.gov fetch failed:\", e)\n",
    "        ct = []\n",
    "\n",
    "rows = []\n",
    "for rec in ct:\n",
    "    def first(x): return x[0] if isinstance(x, list) and x else None\n",
    "    start = to_dt(first(rec.get(\"StartDate\")))\n",
    "    comp = to_dt(first(rec.get(\"CompletionDate\")))\n",
    "    dur_m = (comp - start).days/30.4 if (start and comp) else None\n",
    "    enroll = first(rec.get(\"EnrollmentCount\"))\n",
    "    enroll = int(enroll) if enroll and str(enroll).isdigit() else None\n",
    "    rows.append({\"duration_months\": dur_m, \"enrollment\": enroll})\n",
    "\n",
    "df_ct = pd.DataFrame(rows)\n",
    "med_duration = float(df_ct['duration_months'].dropna().median()) if df_ct['duration_months'].notna().any() else None\n",
    "med_enroll = int(df_ct['enrollment'].dropna().median()) if df_ct['enrollment'].notna().any() else None\n",
    "med_duration, med_enroll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ae9d4e-fcd5-42e1-a33f-cd4884179851",
   "metadata": {},
   "source": [
    "### Context score (feasibility proxy)\n",
    "\n",
    "We convert portfolio context into a **0–1 score**:\n",
    "- **Shorter median duration** → higher score  \n",
    "- **Moderate enrollment** (not extreme) → higher score  \n",
    "\n",
    "These are *illustrative* heuristics to show how portfolio signals can feed governance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ba5484-506d-472d-bc16-e669127535a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp(x, lo=0.0, hi=1.0):\n",
    "    return max(lo, min(hi, x))\n",
    "\n",
    "def context_from_ctgov(med_duration, med_enroll):\n",
    "    # Favor durations closer to ~24 months, with declining scores after ~48m\n",
    "    if med_duration is None:\n",
    "        s_dur = 0.5\n",
    "    else:\n",
    "        s_dur = clamp(1.0 - max(0.0, (med_duration - 24.0)) / 48.0)\n",
    "\n",
    "    # Favor enrollments around ~300; penalize extremes using a triangular shape\n",
    "    if med_enroll is None:\n",
    "        s_enr = 0.5\n",
    "    else:\n",
    "        center, width = 300.0, 500.0\n",
    "        s_enr = clamp(1.0 - abs(med_enroll - center) / width)\n",
    "\n",
    "    return 0.6 * s_dur + 0.4 * s_enr\n",
    "\n",
    "ctgov_context = context_from_ctgov(med_duration, med_enroll)\n",
    "ctgov_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd32658e-3a7c-4ec9-b813-0ed55acfb13f",
   "metadata": {},
   "source": [
    "## 5) CDC public-health timeliness (reuses saved summary if present)\n",
    "\n",
    "This section computes a **timeliness proxy** from CDC data:\n",
    "- Share of records in the last **14 days**\n",
    "\n",
    "If `data/cdc_summary.json` exists, we reuse it; otherwise we fetch from the CDC API directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00113f86-589c-4579-a463-3d3146fb5975",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdc_cache = DATA_DIR / \"cdc_summary.json\"\n",
    "\n",
    "def fetch_cdc(limit=5000):\n",
    "    URL = \"https://data.cdc.gov/resource/9mfq-cb36.json\"\n",
    "    params = {\"$limit\": limit, \"$select\": \"submission_date,state,tot_cases,conf_cases,prob_cases,new_case\"}\n",
    "    r = requests.get(URL, params=params, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "if cdc_cache.exists():\n",
    "    raw = json.loads(cdc_cache.read_text())\n",
    "else:\n",
    "    try:\n",
    "        raw = fetch_cdc(5000)\n",
    "        cdc_cache.write_text(json.dumps(raw))\n",
    "    except Exception as e:\n",
    "        print(\"CDC fetch failed:\", e)\n",
    "        raw = []\n",
    "\n",
    "df_cdc = pd.DataFrame(raw)\n",
    "if not df_cdc.empty and \"submission_date\" in df_cdc.columns:\n",
    "    df_cdc['submission_date'] = pd.to_datetime(df_cdc['submission_date'], errors='coerce')\n",
    "    cdc_timeliness = (df_cdc['submission_date'] >= (pd.Timestamp.utcnow() - pd.Timedelta(days=14))).mean()\n",
    "else:\n",
    "    cdc_timeliness = 0.5\n",
    "\n",
    "cdc_timeliness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24df597-ed24-460a-b607-3bd735925f31",
   "metadata": {},
   "source": [
    "## 6) Combine to **Standards** and **Context** components\n",
    "\n",
    "- **Standards**: OMOP + FHIR + vocab (already aggregated)\n",
    "- **Context**: Blend **CT.gov** (feasibility proxy) and **CDC** (external timeliness) → a single context score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea8ea20-a548-4db7-ae46-4c6df0a50445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_score(ctgov_context, cdc_timeliness, w_ctgov=0.6, w_cdc=0.4):\n",
    "    return float(w_ctgov*float(ctgov_context or 0.0) + w_cdc*float(cdc_timeliness or 0.0))\n",
    "\n",
    "context = context_score(ctgov_context, cdc_timeliness)\n",
    "standards, context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baf5347-933f-4303-97d7-b3e1c617be59",
   "metadata": {},
   "source": [
    "## 7) Final metrics + Expanded Governance Scorecard\n",
    "\n",
    "Weights (illustrative, tune per org):\n",
    "- Completeness 0.25\n",
    "- Consistency 0.15\n",
    "- Timeliness 0.15\n",
    "- Conformity 0.10\n",
    "- **Standards 0.20**\n",
    "- **Context 0.15**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9860ea60-260c-4248-906e-faf3d1ed753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_all = {\n",
    "    **basic,\n",
    "    \"standards\": standards,\n",
    "    \"context\": context\n",
    "}\n",
    "\n",
    "# Custom plot to include the new \"Context\" bar\n",
    "labels = [\"Completeness\",\"Consistency\",\"Timeliness\",\"Conformity\",\"Standards\",\"Context\"]\n",
    "vals = [metrics_all.get(k,0) for k in [\"completeness\",\"consistency\",\"timeliness\",\"conformity\",\"standards\",\"context\"]]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "ax.bar(labels, vals)\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_title(\"Expanded RWD Governance Scorecard\")\n",
    "for i, v in enumerate(vals):\n",
    "    ax.text(i, min(0.98, v + 0.02), f\"{v:.2f}\", ha=\"center\", va=\"bottom\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Reuse score() but with custom weights that include \"context\"\n",
    "def score_with_context(m):\n",
    "    weights = {\"completeness\":0.25,\"consistency\":0.15,\"timeliness\":0.15,\"conformity\":0.10,\"standards\":0.20,\"context\":0.15}\n",
    "    return sum(weights[k]*float(m.get(k,0.0)) for k in weights)\n",
    "\n",
    "overall = score_with_context(metrics_all)\n",
    "metrics_all, overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950f4e55-44e4-4c0e-addc-68c69f7e2e88",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "- **Standards** captures interoperability readiness (OMOP/FHIR/vocab).  \n",
    "- **Context** injects real-world feasibility and external timeliness into governance, grounding go/no-go or investment decisions.  \n",
    "- You can tune weights by therapy area, geography, and evidence strategy.\n",
    "\n",
    "**Next**\n",
    "- Replace regex vocab proxies with real code-set coverage (RxNorm/SNOMED) from cached dictionaries.  \n",
    "- Swap the synthetic FHIR bundle for actual resources; add schema validation.  \n",
    "- Persist summaries from the CT.gov and CDC notebooks into `data/` so this runs offline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
